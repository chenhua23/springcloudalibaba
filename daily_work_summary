## arthas常用过滤，筛选命令：
  watch com.huawei.ict.nbi.kafka.producer.ADCKafkaProducer sendDataToKafka "{params,returnObj}" "params[0].equals('topic') && params[2].indexOf('usernumber')==-1" -x 3
  getstatic com.huawei.ict.nbi.alarm.restful.platform.heartbeat.impl.HeartBeatCkolaServiceImpl isSendHeartBeat
  ognl '@java.lang.System@getProperty("NBI_SCALE")' -X 1

## 远程debug调试：
1.进入docker容器，在/opt/mateinfo/app/bin/catalina.sh中添加以下参数：
JAVA_OPTS="$JAVA_OPTS -Xdebug -Xrunjdwp:transport=dt_socket,address=9689,server=y,suspend=n"
netstat -anp | grep "9689"
查找容器ip：172.18.1.79
2.在容器宿主机执行以下命令：
iptables -t nat -A PREROUTING -i eth0 -p tcp -m tcp --dport 9689 -j DNAT --to-destination 172.18.1.141:9689
3.在idea中配置remote debug：

## 证书生成，转换命令：
# curl下载证书
openssl s_client -showcerts -connect {HOSTNAME}:{PORT} </dev/null 2>/dev/null|openssl x509 -outform PEM >mycertfile.pem
# pem转cert
openssl x509 -in mycertfile.pem -outform der -out lb.cer 

## linux环境调试接口curl命令：
curl -k -X PUT https://192.168.0.30:26335/rest/plat/smapp/v1/oauth/token -H 'Cache-Control: no-cache' -H 'Content-Type: application/json' -d '{"grantType": "password", "userName": "22338177-eb92-4430-b78b-4cff7502bf82", "value": "ce51dfdbc4df56e57fc663ee04ca0f8d" }'
curl -k -X POST https://192.168.0.30:26335/rest/iesalarmadapterrouterservice/v1/om/maccrt/app/api/ict_alarm_interface/queryHistoryAlarmList -H 'Cache-Control: no-cache' -H 'Content-Type: application/json' -H 'x-auth-token: fae46ed4f4386ad4ac1a95a58420bfd3' -d '{"fields": ["alarmname", "alarmid"],"condition": [],"expression": "","sortCondition": {"lastoccurrence": "0"},"start": 0,"limit": 10}'
curl -H "Content-type: application/json" -X POST -d '{"grant_type":"client_credentials","client_id":"","client_secret":""}' https://8.9.113.164:8091/nbi-report-restful/rest/alarm/report1 --cacert /etc/nginx/ssl/tls.crt -v
curl -k -v -u "accessinner:BK3l0c36lF3PkL1x" https://localhost:17138/trustStore

##k8s&&容器操作相关命令：
https://kubernetes.io/zh-cn/docs/reference/kubectl/cheatsheet/
以指定用户登录docker容器：
docker exec -it -u root --privileged 容器id bash
docker exec -it $(docker ps|grep -v pause|grep nbi-alarm|awk '{print $1}') bash
docker cp /home/paas/swagger-annotations-1.6.2.jar 079f7ffc2a38:/opt/mateinfo/app/webapps/nbi-alarm-restful/WEB-INF/lib/
kubectl scale deployment alarmnotification-service --replicas=5 -n kube-system
kubectl 
kubectl get deploy -n kube-system -owide | grep iesalarmada
kubectl get pod -n kube-system -owide | grep iesalarmada
kubectl get job -n kube-system -owide | grep iesalarmada
kubectl describe pod pre-install-iesalarmadapterrouterservice -n kube-system
netstat -antp | grep 8090

## 查找哪个微服务jar包中含有引号内的类：
find ./ -name '*.jar' | xargs grep "org.apache.commons.pool2.impl.GenericObjectPoolConfig"

## javac编译：
javac -g -parameters -encoding utf-8 -classpath .;./class/*;./lib/* Demo.java  
## 重新压缩：
jar cvf0M  report-manage-service.jar .

## nginx相关：
find -name "vhosts"
/usr/local/NSP/sbin/nginx -s reload

## jvm参数设置相关
ADC_JVM_CUSTOM_SCALE="-Xms5600m -Xmx5600m -Xmn4000m -XX:MetaspaceSize=250m -XX:MaxMetaspaceSize=250m -XX:MaxDirectMemorySize=500m -XX:SurvivorRatio=16"

## 不使用arthas的cup 100%排查：
arthas 火焰图
profiler start
...
profiler stop
输出文件所在的位置，生成svg文件，可以直接使用浏览器打开
最后使用浏览器查看
+++++++++++++++++++++++++++++++++++++++++++++++++++++++
原生命令：
1. 使用top查看是否是java程序引起的，获取到pid
2. ps -mp pid -o THREAD,tid,time  查看当前java进程的线程信息
3. 找到线程id，是十进制的的，但是java开发中调试的信息都是16进制，需要转换
4. printf "%x\n" 线程id，输出16进制的线程id
5. jstack 进程id | grep 16进制线程id -A100 
6. 完整堆栈列表

## 不使用arthas的oom排查：
1. 连接到环境（linux），使用jps命令查看java应用
2. 使用jstat -gcutil pid 1000 10  1秒钟展示一次，总共产生10次。查看当前pid占用了哪些空间，到底是哪块快满了？
S0 S2 E O M   FGC 分别代表survivor区，eden区，老年带内存占比，以及Full GC次数
3. 使用arthas分析 dashboard命令查看各种指标
4. 使用heapdump /tmp/dump-1.hprof 导出内存快照到/tmp/dump-1.hprof文件中，底层就是使用jdk的jmap -dump命令导出的
5.下载dump文件，使用visualVM打开下载的文件
6. 分析对象数据，查看对象最多的，点击右键，选择open in new tab；
7. 后点击右侧的GC Root，查看对象来源。
8. 在最后的类点击Select in Thread 分析代码
也可以使用jprofiler分析
***********************java 线上问题处理可以参照：https://blog.csdn.net/GitChat/article/details/79019454

数据库优化工具：mysql6.5以后内置工具
select * from information_schema.optimizer_trace
其他：可以用来查看当前mysql 是否有压力，都在跑什么语句，当前语句耗时多久了，有没有什么慢 SQL 正在执行之类的
show processlist / show full processlist
select * from information_schema.processlist;

尚硅谷云原生,笔记地址
https://www.yuque.com/leifengyang/oncloud

#
# Copyright 1999-2021 Alibaba Group Holding Ltd.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

#*************** Spring Boot Related Configurations ***************#
### Default web context path:
server.servlet.contextPath=/nacos
### Include message field
server.error.include-message=ALWAYS
### Default web server port:
server.port=3333

#*************** Network Related Configurations ***************#
### If prefer hostname over ip for Nacos server addresses in cluster.conf:
# nacos.inetutils.prefer-hostname-over-ip=false

### Specify local server's IP:
# nacos.inetutils.ip-address=


#*************** Config Module Related Configurations ***************#
### If use MySQL as datasource:
### Deprecated configuration property, it is recommended to use `spring.sql.init.platform` replaced.
# spring.datasource.platform=mysql
# spring.sql.init.platform=mysql

### Count of DB:
# db.num=1

### Connect URL of DB:
# db.url.0=jdbc:mysql://127.0.0.1:3306/nacos?characterEncoding=utf8&connectTimeout=1000&socketTimeout=3000&autoReconnect=true&useUnicode=true&useSSL=false&serverTimezone=UTC
# db.user.0=nacos
# db.password.0=nacos
spring.datasource.platform=mysql

db.num=1
db.url.0=jdbc:mysql://localhost:3306/nacos_config?characterEncoding=utf8&connectTimeout=1000&socketTimeout=3000&autoReconnect=true
db.user=root
db.password=mysql


### Connection pool configuration: hikariCP
db.pool.config.connectionTimeout=30000
db.pool.config.validationTimeout=10000
db.pool.config.maximumPoolSize=20
db.pool.config.minimumIdle=2

#*************** Naming Module Related Configurations ***************#

### If enable data warmup. If set to false, the server would accept request without local data preparation:
# nacos.naming.data.warmup=true

### If enable the instance auto expiration, kind like of health check of instance:
# nacos.naming.expireInstance=true

### Add in 2.0.0
### The interval to clean empty service, unit: milliseconds.
# nacos.naming.clean.empty-service.interval=60000

### The expired time to clean empty service, unit: milliseconds.
# nacos.naming.clean.empty-service.expired-time=60000

### The interval to clean expired metadata, unit: milliseconds.
# nacos.naming.clean.expired-metadata.interval=5000

### The expired time to clean metadata, unit: milliseconds.
# nacos.naming.clean.expired-metadata.expired-time=60000

### The delay time before push task to execute from service changed, unit: milliseconds.
# nacos.naming.push.pushTaskDelay=500

### The timeout for push task execute, unit: milliseconds.
# nacos.naming.push.pushTaskTimeout=5000

### The delay time for retrying failed push task, unit: milliseconds.
# nacos.naming.push.pushTaskRetryDelay=1000

### Since 2.0.3
### The expired time for inactive client, unit: milliseconds.
# nacos.naming.client.expired.time=180000

#*************** CMDB Module Related Configurations ***************#
### The interval to dump external CMDB in seconds:
# nacos.cmdb.dumpTaskInterval=3600

### The interval of polling data change event in seconds:
# nacos.cmdb.eventTaskInterval=10

### The interval of loading labels in seconds:
# nacos.cmdb.labelTaskInterval=300

### If turn on data loading task:
# nacos.cmdb.loadDataAtStart=false


#*************** Metrics Related Configurations ***************#
### Metrics for prometheus
#management.endpoints.web.exposure.include=*

### Metrics for elastic search
management.metrics.export.elastic.enabled=false
#management.metrics.export.elastic.host=http://localhost:9200

### Metrics for influx
management.metrics.export.influx.enabled=false
#management.metrics.export.influx.db=springboot
#management.metrics.export.influx.uri=http://localhost:8086
#management.metrics.export.influx.auto-create-db=true
#management.metrics.export.influx.consistency=one
#management.metrics.export.influx.compressed=true

#*************** Access Log Related Configurations ***************#
### If turn on the access log:
server.tomcat.accesslog.enabled=true

### The access log pattern:
server.tomcat.accesslog.pattern=%h %l %u %t "%r" %s %b %D %{User-Agent}i %{Request-Source}i

### The directory of access log:
server.tomcat.basedir=file:.

#*************** Access Control Related Configurations ***************#
### If enable spring security, this option is deprecated in 1.2.0:
#spring.security.enabled=false

### The ignore urls of auth
nacos.security.ignore.urls=/,/error,/**/*.css,/**/*.js,/**/*.html,/**/*.map,/**/*.svg,/**/*.png,/**/*.ico,/console-ui/public/**,/v1/auth/**,/v1/console/health/**,/actuator/**,/v1/console/server/**

### The auth system to use, currently only 'nacos' and 'ldap' is supported:
nacos.core.auth.system.type=nacos

### If turn on auth system:
nacos.core.auth.enabled=false

### Turn on/off caching of auth information. By turning on this switch, the update of auth information would have a 15 seconds delay.
nacos.core.auth.caching.enabled=true

### Since 1.4.1, Turn on/off white auth for user-agent: nacos-server, only for upgrade from old version.
nacos.core.auth.enable.userAgentAuthWhite=false

### Since 1.4.1, worked when nacos.core.auth.enabled=true and nacos.core.auth.enable.userAgentAuthWhite=false.
### The two properties is the white list for auth and used by identity the request from other server.
nacos.core.auth.server.identity.key=
nacos.core.auth.server.identity.value=

### worked when nacos.core.auth.system.type=nacos
### The token expiration in seconds:
nacos.core.auth.plugin.nacos.token.cache.enable=false
nacos.core.auth.plugin.nacos.token.expire.seconds=18000
### The default token (Base64 String):
nacos.core.auth.plugin.nacos.token.secret.key=

### worked when nacos.core.auth.system.type=ldap，{0} is Placeholder,replace login username
#nacos.core.auth.ldap.url=ldap://localhost:389
#nacos.core.auth.ldap.basedc=dc=example,dc=org
#nacos.core.auth.ldap.userDn=cn=admin,${nacos.core.auth.ldap.basedc}
#nacos.core.auth.ldap.password=admin
#nacos.core.auth.ldap.userdn=cn={0},dc=example,dc=org
#nacos.core.auth.ldap.filter.prefix=uid
#nacos.core.auth.ldap.case.sensitive=true


#*************** Istio Related Configurations ***************#
### If turn on the MCP server:
nacos.istio.mcp.server.enabled=false

#*************** Core Related Configurations ***************#

### set the WorkerID manually
# nacos.core.snowflake.worker-id=

### Member-MetaData
# nacos.core.member.meta.site=
# nacos.core.member.meta.adweight=
# nacos.core.member.meta.weight=

### MemberLookup
### Addressing pattern category, If set, the priority is highest
# nacos.core.member.lookup.type=[file,address-server]
## Set the cluster list with a configuration file or command-line argument
# nacos.member.list=192.168.16.101:8847?raft_port=8807,192.168.16.101?raft_port=8808,192.168.16.101:8849?raft_port=8809
## for AddressServerMemberLookup
# Maximum number of retries to query the address server upon initialization
# nacos.core.address-server.retry=5
## Server domain name address of [address-server] mode
# address.server.domain=jmenv.tbsite.net
## Server port of [address-server] mode
# address.server.port=8080
## Request address of [address-server] mode
# address.server.url=/nacos/serverlist

#*************** JRaft Related Configurations ***************#

### Sets the Raft cluster election timeout, default value is 5 second
# nacos.core.protocol.raft.data.election_timeout_ms=5000
### Sets the amount of time the Raft snapshot will execute periodically, default is 30 minute
# nacos.core.protocol.raft.data.snapshot_interval_secs=30
### raft internal worker threads
# nacos.core.protocol.raft.data.core_thread_num=8
### Number of threads required for raft business request processing
# nacos.core.protocol.raft.data.cli_service_thread_num=4
### raft linear read strategy. Safe linear reads are used by default, that is, the Leader tenure is confirmed by heartbeat
# nacos.core.protocol.raft.data.read_index_type=ReadOnlySafe
### rpc request timeout, default 5 seconds
# nacos.core.protocol.raft.data.rpc_request_timeout_ms=5000

#*************** Distro Related Configurations ***************#

### Distro data sync delay time, when sync task delayed, task will be merged for same data key. Default 1 second.
# nacos.core.protocol.distro.data.sync.delayMs=1000

### Distro data sync timeout for one sync data, default 3 seconds.
# nacos.core.protocol.distro.data.sync.timeoutMs=3000

### Distro data sync retry delay time when sync data failed or timeout, same behavior with delayMs, default 3 seconds.
# nacos.core.protocol.distro.data.sync.retryDelayMs=3000

### Distro data verify interval time, verify synced data whether expired for a interval. Default 5 seconds.
# nacos.core.protocol.distro.data.verify.intervalMs=5000

### Distro data verify timeout for one verify, default 3 seconds.
# nacos.core.protocol.distro.data.verify.timeoutMs=3000

### Distro data load retry delay when load snapshot data failed, default 30 seconds.
# nacos.core.protocol.distro.data.load.retryDelayMs=30000

### enable to support prometheus service discovery
#nacos.prometheus.metrics.enabled=true

### Since 2.3
#*************** Grpc Configurations ***************#

## sdk grpc(between nacos server and client) configuration
## Sets the maximum message size allowed to be received on the server.
#nacos.remote.server.grpc.sdk.max-inbound-message-size=10485760

## Sets the time(milliseconds) without read activity before sending a keepalive ping. The typical default is two hours.
#nacos.remote.server.grpc.sdk.keep-alive-time=7200000

## Sets a time(milliseconds) waiting for read activity after sending a keepalive ping. Defaults to 20 seconds.
#nacos.remote.server.grpc.sdk.keep-alive-timeout=20000


## Sets a time(milliseconds) that specify the most aggressive keep-alive time clients are permitted to configure. The typical default is 5 minutes
#nacos.remote.server.grpc.sdk.permit-keep-alive-time=300000

## cluster grpc(inside the nacos server) configuration
#nacos.remote.server.grpc.cluster.max-inbound-message-size=10485760

## Sets the time(milliseconds) without read activity before sending a keepalive ping. The typical default is two hours.
#nacos.remote.server.grpc.cluster.keep-alive-time=7200000

## Sets a time(milliseconds) waiting for read activity after sending a keepalive ping. Defaults to 20 seconds.
#nacos.remote.server.grpc.cluster.keep-alive-timeout=20000

## Sets a time(milliseconds) that specify the most aggressive keep-alive time clients are permitted to configure. The typical default is 5 minutes
#nacos.remote.server.grpc.cluster.permit-keep-alive-time=300000









